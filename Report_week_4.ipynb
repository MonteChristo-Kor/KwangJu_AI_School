{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Report_week_4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MonteChristo-Kor/KwangJu_AI_School/blob/master/Report_week_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxkL6PjwsI6L",
        "colab_type": "text"
      },
      "source": [
        "# **4주차 과제**\n",
        "- 용어 정리\n",
        "- 딥러닝 강의 클론 코딩\n",
        "- 딥러닝 순전파 & 역전파 계산"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixEtDe6_uGgI",
        "colab_type": "text"
      },
      "source": [
        "## **1. 용어 정리**\n",
        "\n",
        "다음 제시된 단어의 정의(설명)를 정리하여 작성 하세요.\n",
        "\n",
        "* 2문장 이상 작성 해 주세요. \n",
        "* 주제(단어)와 크게 벗어나지만 않는다면 정답처리 됩니다.\n",
        "* 강의 뿐 아니라 기타 레퍼런스를 참고하여 작성하셔도 됩니다. (기타 레퍼런스를 참고하신 경우, 해당 레퍼런스를 정리하여 하단에 작성해 주세요.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8YJNKG_v65A",
        "colab_type": "text"
      },
      "source": [
        "### <u>**MCP 뉴런**</u>\n",
        "　인공지능이라는 즉 인간이 가공한 지능을 구현하기 위해서는 가장 기본적으로 생각할 수 있는 게 인간의 뇌를 모방하는 것이다. 그 동안 인간의 뇌와 생각의 연관관계에 대해서 밝혀진 것이 많지 않았고, 그것을 다시 구현하기 위한 수학적 표현도 불완전했다. \n",
        "<br><br>\n",
        "　하지만 1943년 워런 맥컬록(Warren McCulloch)과 월터 피츠(Walter Pitts)는 처음으로 간소화된 뇌의 뉴런 개념을 발표했다. <br>\n",
        "　이는 인공지능의 중요한 이정표로 지능을 만들기 위한 가장 기초적인 단계인 **인간의 뇌를 모방하기 위한 최소한의 수학적 모델을 구현**했다는데 의의가 있고, 향후 인공지능 개발에 중요한 토대가 되었다. 이를 **맥컬록(MC) - 피츠(P) 즉 MCP의 뉴런 모델**이라고 한다. <br><br>\n",
        "　MCP 뉴런 즉 MCP 모델은 선형 임계값 게이트라고도 알려져있고, 입력값과 가중치를 곱한 값들의 합으로 계산해서 그 값이 임계값보다 크면 활성화되는 구조이다. \n",
        "<br><br>\n",
        "![MCP 모델](https://github.com/MonteChristo-Kor/Self_Study_AI/blob/master/%EB%89%B4%EB%9F%B0.png?raw=true)\n",
        "<br><br>\n",
        "> 출처 : https://yamerong.tistory.com/43\n",
        "------\n",
        "<br>\n",
        "\n",
        "### <u>**퍼셉트론**</u>\n",
        "　퍼셉트론은 **1957년 프랑크 로젠블라트(Frank Rosenblatt)가 고안한 알고리즘**이다. 이는 인공 신경망의 기원이 되는 알고리즘으로 MCP 모델로 인해 개념적 인공지능의 알고리즘이 대두되고 그것을 실제로 구현한 초기의 모델이라고 할 수 있다. \n",
        "<br>\n",
        "　뉴런의 원리와 동일하게 퍼셉트론 역시 다수의 신호를 입력받아 하나의 신호를 출력하되 각각의 신호에 가중치를 더하고 그 전체 값이 임계치를 넘으면 출력을 하고 넘지 않으면 출력하지 않는다. **가중치는 각 신호가 결과에 주는 영향력을 조절하는 용소로 작용하며, 가중치가 클수록 그 신호가 중요하다는 의미**이다. \n",
        "<br>\n",
        "　퍼셉트론의 출력값은 0과 1로 이루어져 있기 때문에 1차원의 선 즉 선형으로 분리가 되므로 **선형 분류 모형**이라고 할 수 있다. 즉 경계선을 기준으로 경계선 초과는 A, 경계선 미만은 B 이런식으로 분류를 한다고 볼 수 있다. \n",
        "<br><br>\n",
        "![퍼셉트론 분류의 예](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/Perceptron_example.svg/500px-Perceptron_example.svg.png?raw=true)\n",
        "<br><br>\n",
        "#### 　**퍼셉트론 한계점**\n",
        "　퍼셉트론은 1차원의 선형으로 분리를 하다보니 그래프로 표현했을 때 1차원의 선분으로 분리를 할 수 없는 구조의 경우 구분자에 대한 값이 실제로는 거의 구분되지 않는 경우가 있다. 특히 유명한 문제로 **XOR 표현 불가의 문제**가 있다.\n",
        "<br><br>\n",
        "![XOR 회로](http://ecee.colorado.edu/~ecen4831/lectures/xor2.gif?raw=true)\n",
        "<br>　　(XOR 그래프는 단층 퍼셉트론 즉 초기 퍼셉트론 모델로는 구현이 안됐다.)\n",
        "<br><br>\n",
        "> 출처 : https://sacko.tistory.com/10\n",
        "---\n",
        "<br>\n",
        "\n",
        "### <u>**역전파**</u>\n",
        "　역전파란 퍼셉트론 이론에서 XOR 논리를 구현할 수 없음에 대해 보완하기 위해 나온 방법론이다. 1969년 MIT AI Lab 창시자인 Marvin Minsky 교수가 XOR 문제를 풀 수 없다는 문제 제기에 대해 1974년 하버드 대학교 박사과정이었던 Paul Werbos가 해법으로 제시했던 개념이 오류 역전파 개념이다. \n",
        "<br>\n",
        "　XOR 퍼셉트론 문제를 해결하기 위해서는 **다층 퍼셉트론(Multi Layer Perceptron, MLP)**를 구현해야 하는데 그 방법론으로 나온 것이 오류 역전파 개념이다. \n",
        "<br>\n",
        "　통상적인 퍼셉트론은 입력층에서 시작해서 가중치와 함께 은닉층을 거쳐 은닉층에서 가중치와 함께 출력층으로 신호가 전달된다. 이를 **순전파(Feedforward)**라고 한다. 하지만 최종 값에 대한 오차가 발생했을 때, 이를 수정하기 위한 개념이 필요했고, 그것을 오류 역전파로 구현한다. \n",
        "<br>\n",
        "　역전파의 순서는 \n",
        "<ol>\n",
        "1. 주어진 가중치 값을 이용해 출력층에 도달한 값을 계산<br>\n",
        "2. 발생한 오차에 대해 가중치로 미분한 값을 기존 가중치에서 빼줌 (경사하강법 이용)<br>\n",
        "3. 2번 단계를 전 단계의 가중치에 대해 적용<br>\n",
        "4. 1번 단계부터 3번 단계까지 주어진 학습 횟수까지 혹은 주어진 허용오차값에 도달할때까지 진행<br>\n",
        "</ol>\n",
        "<br>\n",
        "　각 단계를 도식화하면 아래와 같다.<br>\n",
        "\n",
        "![순전파와 오류 역전파](https://github.com/MonteChristo-Kor/Self_Study_AI/blob/master/%EC%88%9C%EC%A0%84%ED%8C%8C%EC%99%80%20%EC%97%AD%EC%A0%84%ED%8C%8C.PNG?raw=true)\n",
        "<br><br>\n",
        "\n",
        "#### 　**오류 역전파의 한계점**\n",
        "　은닉층이 더 늘어나면 그로 인해 더 좋은 성능이 발휘될 것이라고 예상했지만 은닉층을 추가하거나 은닉층의 노드를 늘려 역전파 알고리즘으로 학습시키면 오히려 성능이 저하됐다. <br>\n",
        "　역전파 알고리즘으로 심층 신경망을 학습시킬 때 겪는 어려움은 아래와 같다.<br>\n",
        "<ul>1. 그래디언트 손실<br>\n",
        "2. 과적합<br>\n",
        "3. 많은 계산량<br>\n",
        "</ul><br>\n",
        "　이와 같은 문제점들이 발생하는 이유는 신경망의 계층을 깊게 만들면 신경망이 제대로 학습되지 않기 때문이었다.<br> \n",
        "　이를 개선하기 위해서 2000년대 나온 기술이 딥러닝 기술이 등장하였다.\n",
        "<br><br>\n",
        "\n",
        "> 출처 : https://m.blog.naver.com/samsjang/221033626685\n",
        "\n",
        "----\n",
        "<br>\n",
        "\n",
        "### <u>**강화학습**</u>\n",
        "　강화학습은 최적 제어(Optimal Control) 역사에 뿌리를 두고 있다. 1950ㄴ년대 다이나믹 프로그래밍으로부터 시작되는데 제한된 문제를 작고 해결할 수 있는 하위 문제로 구조화한다는 리차드 벨먼(Richard Bellman)이 창안한 구조화된 문제 접근법이다. \n",
        "<br>\n",
        "　1992년 시차 모델을 기반으로 한 Tesauro의 백 감몬 프로그램 등 RL과 제어 사이의 연결에 대한 알고리즘에 대한 많은 연구가 있었는데, 이러한 알고리즘을 강화학습이라고 부를 수 있다. \n",
        "<br>\n",
        "　강화학습은 한 마디로 이야기해서 현재 상태를 파악하고, 환경과 상호작용하며 보상을 최대화할 수 있는 방법으로 행동을 결정하고 행동하는 것을 의미한다. \n",
        "<br>\n",
        "　강화학습은 다음과 같은 요소들로 이루어져있다. \n",
        "<br><ul>\n",
        "- **에이전트(Agent)** : 주언진 문제 상황에서 의사결정을 하고 행동하는 주체. 게임에서는 플레이어가 조작하는 캐릭터, 또는 조작하는 플레이어 본인이 에이전트라고 할 수 있다. \n",
        "- **환경(Environment)** : 에이전트의 의사결정 반영이 되는 곳이고, 다시 반영된 정보를 에이전트에게 전달하는 것을 환경이라고 한다. \n",
        "- **상태(State)** : 현재 상황을 나타내는 정보\n",
        "- **행동(Action)** : 현재 상황에서 에이전트가 하는 것\n",
        "- **보상(Reward)** : 행동의 좋고 나쁨을 알려주는 정보\n",
        "- **초기 상태(Initial state)** : 에이전트가 처음으로 환경과 상호작용 할 때의 상태\n",
        "- **종료상태(Terminal state)** : 더 이상의 행동이 불가능한 상태\n",
        "- **에피소드(episode)** : 초기 상태(Initial state)부터 종료 상태(Terminal state)까지 에이전트가 거친 상태, 행동, 보상 등의 Sequence 즉 전체적인 과정을 의미하고, Rollout, Trajectory라고  부르기도 한다. \n",
        "\n",
        "</ul><br>\n",
        "\n",
        "![강화학습 개요](http://www.agilesoda.com/resources/ecoletree/img/kr/home/imgAiTrand02.png?raw=true)\n",
        "<br>\n",
        "\n",
        "　강화학습은 보상을 최대치로 얻을 수 있는 방향으로 행동하므로 단기적인 보상뿐만 아니라 각 행동이 결과적으로 얼마나 가치 있는지 판단하기 위해서는 누적 보상 값을 예측할 수 있어야 한다. 이를 수학적으로 정의한 것이 **가치 함수**이다. \n",
        "<br>\n",
        "　가치 함수 식은 아래와 같다. <br>\n",
        "![가치 함수](https://github.com/MonteChristo-Kor/Self_Study_AI/blob/master/%EA%B0%80%EC%B9%98%20%ED%95%A8%EC%88%98.PNG?raw=true)\n",
        "<br>\n",
        "　여기서 T는 종료 시점의 시각이고, γ는 Discount Factor이다. 0에서 1사의 값을 취하게 되고, 0에 가까울수록 미래에 받을 수 잇는 보상보다 지금 당장 얻을 수 잇는 보상에 더 가중치를 주게 되고, 1에 가까울수록 즉각적인 보상과 미래에 받을 수 있는 보상을 동등하게 취급한다. \n",
        "<br>\n",
        "　위에서 정의한 가치 함수를 실제로 구하는 방법은 크게 Monte Carlo로 계열과 Temporal Difference(TD) 계열이 있다. Monte Carlo 방식은 하나의 에피소드가 끝난 후 각 단계별로 대응되는 누적 보상을 구해서 Target Value와 가까워지게 하는 것을 말한다. \n",
        "<br>\n",
        "　**Monte Carlo 방식**은 장기나 바둑 등 하나의 에피소드가 끝나고 다시 반복하는 게임의 경우 적용하는데 문제가 없지만 마인크래프트 등 **끝도 없이 이어지는 게임들의 경우에는 적용에 무리가 있다.** 이러한 것을 보완하기 위해 TD 계열의 방식을 이용한다. \n",
        "<br>\n",
        "\n",
        "#### 　**강화학습의 한계**\n",
        "　강화학습은 타임스톤을 든 닥터스트레인지처럼 끊임없이 반복하면서 학습하며, 게임의 룰을 파악하고, 그 속에서 최상의 수를 찾아나가는 알고리즘이다. 즉 그만큼 컴퓨팅 파워와 시간을 요한다는 것이다. <br>\n",
        "　게임 등의 시뮬레이션을 통해서 강화학습을 한다면, 일반적인 그래픽 카드 사용시 수백년에서 수천년까지 걸릴 수 있다. 실제로 물리 시뮬레이션 캐릭터의 제어 논문을 보면 게임 물리엔진 속에서 간단한 동작 하나를 훈련시키는데도 몇 일씩 걸린다고 보고 되었다. 그러므로 **한 개인이 손을 대기에는 아직은 컴퓨팅 파워 확보에 대한 비용 문제**로 현실적으로 어렵다는 한계점이 있다. <br>\n",
        "　하지만 컴퓨터의 초창기에서 지금까지 눈부신 발전과 단가 인하를 이뤄왔듯 하드웨어의 발전 필요성을 또 한번 더 역설한 사례라고 생각하고 시간이 흘러 관련된 프로세서와 하드웨어가 발전하게 되면 개인과 팀 단위에서도 강화학습을 자유롭게 활용할 수 있는 시기가 올 수 있지 않을까 기대한다. \n",
        "<br><br>\n",
        "\n",
        "> 출처 : http://www.secmem.org/blog/2019/12/15/RL-key-concepts/\n",
        "\n",
        "---\n",
        "<br>\n",
        "\n",
        "### <u>**과적합**</u>\n",
        "<br>\n",
        "　머신러닝에서 **과적합(Overfitting)**은 **학습데이터를 과하게 잘 학습하는 것**을 뜻한다. 일반적으로 학습 데이터는 실제 데이터의 부분집합인 경우가 대부분이다. 따라서, 학습 데이터에서 오차가 감소하지만, 실제 데이터에서는 오차가 증가하는 지점이 존재할 수 있다. <br>\n",
        "　이를 테면, 노란색 고양이군을 보며 고양이를 학습했다면, 검은색이나 흰색 고양이는 고양이로 인식하지 못하는 문제가 발생할 수 있다. 혹은 삽살개의 다양한 데이터를 가지고 개라는 객체를 학습했을 때, 과한 학습은 걸레를 보고도 개로 인식하는 문제들이 발생할 수 있다.\n",
        "<br>\n",
        "\n",
        "![과적합](https://upload.wikimedia.org/wikipedia/commons/thumb/1/19/Overfitting.svg/250px-Overfitting.svg.png?raw=true)\n",
        "<br><br>\n",
        "\n",
        "　머신러닝을 진행하다보면 과적합이 거의 해결이 불가능한 수준의 문제인 경우가 많이 발생하는데, 해결이 불가능하거나 불가능한 이유는 아래와 같다. \n",
        "\n",
        "<br><ul>\n",
        "- 모든 학습 데이터는 실제 데이터 군의 부분 집합이며, 이 세상의 모든 데이터를 빈틈없이 수집하는 것은 불가능하다. 즉 플라톤이 이야기한 이데아의 현상이다. \n",
        "- 만약 실제 데이터를 모두 수집하여도 모든 데이터를 학습 시키기 위한 시간이 측정 불가능한 수준으로 증가한다. \n",
        "- 학습 데이터만 가지고 실제 데이터의 오차가 증가하는 지점을 예측하는 것은 매우 어렵거나 불가능하다. \n",
        "</ul><br>\n",
        "\n",
        "#### **과적합을 해결하기 위한 방안**\n",
        "　가장 직관적이면서도 많이 이용된 방법은 최적화 기법을 이용하는 것이다. 그 중에서도 서포트 벡터 머신 방법이 있는데, 이 방법은 데이터를 분류하기 위한 decision surface를 찾는 동시에 각 데이터와 decision surface간의 거리(margin)를 최대화하는 방식으로 학습을 진행한다. <br>\n",
        "　![SVM](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile9.uf.tistory.com%2Fimage%2F215C923C57347528189612?raw=true)\n",
        "<br>\n",
        "> 출처 : https://untitledtblog.tistory.com/68\n",
        "\n",
        "----\n",
        "\n",
        "<br>\n",
        "\n",
        "### <u>**차원의 저주**</u>\n",
        "　**차원의 저주**란 **데이터 학습을 위해 차원이 증가하면서 학습 데이터 수가 차원의 수보다 적어져 성능이 저하되는 현상으로 관측치 수보다 변수의 수가 많아지면 발생**한다. <br>\n",
        "　KNN 알고리즘이 취약한데 차원이 커질수록 이웃의 점들이 점점 멀어져가면서 데이터 공간을 채우는 비율이 줄어들기 때문에 이를 채우기 위한 데이터 건수도 증가하게 된다. <br>\n",
        "　그러면서 충분히 큰 공간에 적은 데이터로만 공간을 표현하기 때문에 과적합(Overfitting)이 발생할 수 있다. <br>\n",
        "　\n",
        "![차원의 저주](https://i0.wp.com/thesciencelife.com/wp-content/uploads/2017/10/f2.png?resize=768%2C768?raw=true)\n",
        "<br><br>\n",
        "\n",
        "#### 　**해결방법**\n",
        "\n",
        "##### 　　**1. 차원축소**\n",
        "<br>\n",
        "　대표적인 해결 방법으로는 **차원 축소** 방법이 있다. 차원 축소란 말 그대로, **차원의 수를 줄이는 것, 즉 변수의 수를 줄이는 것**이다. 차원의 축소를 통해 차원의 저주를 탈피할 수 있고, 시각화의 용이성을 얻을 수 있다.\n",
        "　차원의 축소를 구현하는 방법은 아래와 같이 두 가지가 있다. \n",
        "<br><ul>\n",
        "- **Feature Selection** : 변수 선택 방법이고, 가지고 잇는 변수들 중에 중요한 변수만 몇 개 고르고 나머지는 버리는 방법이다. 중요한 변수를 찾을 때 주로 쓰는 방법에는 **상관분석(Correlation)**이 있다. \n",
        "- **Feature Extraction** : 변수 추출 방법이고, 이는 변수를 고르는게 아니라 변수를 섞어서 이 모든 변수들을 표현할 수 있는 새로운 변수를 만들어서 통폐합 시키는 방식으로 **주성분분석(PCA, Principal Component Analysis)**이 있다. \n",
        "</ul><br> <br>\n",
        "\n",
        "> 출처 : https://kkokkilkon.tistory.com/127\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-zfFXLCy6jD",
        "colab_type": "text"
      },
      "source": [
        "## **2. 딥러닝 강의 클론 코딩**\n",
        "\n",
        "####__퍼셉트론 구조 구현하기__ \n",
        "딥러닝 강의(__딥러닝 원리[1] 3:15 ~ 5:15 부분__)를 보고 코드를 따라 치며 출력 결과를 만드세요.\n",
        " \n",
        "\n",
        "* 하나의 코드셀에 해당 코드를 한번에 다 적어서 실행해주세요 (__그렇게 하지 않을 경우, 아래 이미지와 같은 출력값이 나오지 않을 수 있습니다__)\n",
        "\n",
        "*__주의!__ 실제로 코딩해서 출력해보면 강의에 나온 출력 결과와 다르게 나옵니다!!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubuRFy0oxlyJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "df8cc714-1f9e-4b95-e14a-636170dc9136"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.compat.v1.set_random_seed(2020)\n",
        "x = 1\n",
        "y = 0\n",
        "w = tf.random.normal([1], 0, 1)\n",
        "#b = tf.random.normal([1], 0, 1)\n",
        "\n",
        "import math \n",
        "def sigmoid(x) :\n",
        "  return 1 / (1 + math.exp(-x))\n",
        "\n",
        "output = sigmoid(x*w)\n",
        "print(output)\n",
        "\n",
        "for i in range(1000) :\n",
        "  output = sigmoid(x * w)\n",
        "  error = y - output\n",
        "  w = w + x * 0.1 * error\n",
        "  #b = b + 1 * 0.1 * error\n",
        "\n",
        "  if i % 100 == 99 :\n",
        "    print(\"학습 횟수 :\", i, \"Error : \", error, \"예측 결과 : \", output)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.47477188589261\n",
            "학습 횟수 : 99 Error :  -0.10010598284299604 예측 결과 :  0.10010598284299604\n",
            "학습 횟수 : 199 Error :  -0.05178399422833116 예측 결과 :  0.05178399422833116\n",
            "학습 횟수 : 299 Error :  -0.034590451977903586 예측 결과 :  0.034590451977903586\n",
            "학습 횟수 : 399 Error :  -0.02588962752851373 예측 결과 :  0.02588962752851373\n",
            "학습 횟수 : 499 Error :  -0.020658699939863617 예측 결과 :  0.020658699939863617\n",
            "학습 횟수 : 599 Error :  -0.017174253993457355 예측 결과 :  0.017174253993457355\n",
            "학습 횟수 : 699 Error :  -0.014689506449480992 예측 결과 :  0.014689506449480992\n",
            "학습 횟수 : 799 Error :  -0.012829497265431342 예측 결과 :  0.012829497265431342\n",
            "학습 횟수 : 899 Error :  -0.011385568271837804 예측 결과 :  0.011385568271837804\n",
            "학습 횟수 : 999 Error :  -0.010232493309882492 예측 결과 :  0.010232493309882492\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QByB7BsX3zo5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr0HVRk8fOom",
        "colab_type": "text"
      },
      "source": [
        "## 3. 딥러닝 순전파 & 역전파 계산\n",
        "\n",
        "딥러닝 강의(__딥러닝 원리[2] 0:55 ~ 4:32 부분__)에 나오는 순전파 & 역전파 계산에 대한 문제 입니다.\n",
        "\n",
        "해당 영상과 다음 이미지를 참고하여 다음 2가지 물음에 답하세요.\n",
        "\n",
        "\n",
        "(1) 학습률이 0.2 일 경우 출력층의 노드값\n",
        "\n",
        "(2) 학습률이 0.1과 0.2 중 기대출력값이 지도데이터 \"3\"과 더 가까운 학습률은?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpwPFWhOUzww",
        "colab_type": "text"
      },
      "source": [
        "![대체 텍스트](https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ff54dfd45-92ec-44ae-9616-6949d2484a45%2F_2020-06-10__5.22.03.png?table=block&id=ee05da89-3ceb-4ad9-a2d3-c9f68d24d1d9&width=3580&cache=v2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2OVY7w5U3CI",
        "colab_type": "text"
      },
      "source": [
        "## (1) 학습률이 0.2 일 경우 출력층의 노드값 : \n",
        "<br>\n",
        "\n",
        "###**답 : 1.6**\n",
        "\n",
        "<br>\n",
        "\n",
        "## (2) 학습률이 0.1과 0.2 중 기대출력값이 지도데이터 \"3\"과 더 가까운 학습률은?\n",
        "<br>\n",
        "\n",
        "###**답 : 학습률 0.1**"
      ]
    }
  ]
}